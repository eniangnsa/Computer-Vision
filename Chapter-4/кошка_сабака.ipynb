{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets, models\n",
    "# import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = '/Users/macbookpro/Desktop/AI SIBERIA/Computer Vision /Chapter-4/dataset/training_set/training_set'\n",
    "test_data_dir = '/Users/macbookpro/Desktop/AI SIBERIA/Computer Vision /Chapter-4/dataset/test_set/test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a Dataset class for the data\n",
    "class cats_dogs(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        super().__init__()\n",
    "        cats = glob(folder+'/cats/*.jpg')\n",
    "        dogs = glob(folder+'/dogs/*.jpg')\n",
    "        self.fpaths = cats + dogs\n",
    "        from random import shuffle, seed; seed(10); shuffle(self.fpaths)\n",
    "        self.targets = [fpath.split('/')[-1].startswith('dog') for fpath in self.fpaths] # dogs=1, cats =0\n",
    "    def __len__(self): return len(self.fpaths)\n",
    "    def __getitem__(self, index):\n",
    "        f = self.fpaths[index]\n",
    "        target = self.targets[index]\n",
    "        im = (cv2.imread(f)[:,:,::-1])\n",
    "        im = cv2.resize(im, (224, 224))\n",
    "        return torch.tensor(im/255).permute(2,0,1).float(), torch.tensor([target]).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m data \u001b[38;5;241m=\u001b[39m cats_dogs(train_data_dir)\n\u001b[0;32m----> 2\u001b[0m im, label \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m200\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mcats_dogs.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 12\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index]\n\u001b[1;32m     14\u001b[0m     im \u001b[38;5;241m=\u001b[39m (cv2\u001b[38;5;241m.\u001b[39mimread(f)[:,:,::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "data = cats_dogs(train_data_dir)\n",
    "im, label = data[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im.permute(1,2,0))\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function for the convolution that will be used in building the architecture\n",
    "def conv_layer(input_channel, number_output, kernel_size, stride=1):\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(input_channel, number_output, kernel_size),\n",
    "        nn.ReLU(),\n",
    "        nn.BatchNorm2d(number_output),\n",
    "        nn.MaxPool2d(2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the model architecture\n",
    "def get_model():\n",
    "    model  = nn.Sequential(\n",
    "        conv_layer(3, 64, 3),\n",
    "        conv_layer(64, 512, 3),\n",
    "        conv_layer(512, 512, 3),\n",
    "        conv_layer(512, 512, 3),\n",
    "        conv_layer(512, 512, 3),\n",
    "        conv_layer(512, 512, 3),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(512, 1),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "    \n",
    "    loss_fn = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, loss_fn, optimizer = get_model()\n",
    "\n",
    "# model summary\n",
    "summary(model, torch.zeros(1,3,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train = cats_dogs(train_data_dir)\n",
    "    trn_dl = DataLoader(train, batch_size=32, shuffle=True, drop_last=True)\n",
    "    val = cats_dogs(test_data_dir)\n",
    "    val_dl = DataLoader(val, batch_size=32, shuffle=True, drop_last=True)\n",
    "    return trn_dl, val_dl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are ignoring the last batch by setting drop_last = True. We do this because the size of the last batch  may not be like that of the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to train the model on a batch of data\n",
    "def train_batch(x, y, model, opt, loss_fn):\n",
    "    model.train()\n",
    "    prediction  = model(x)\n",
    "    batch_loss = loss_fn(prediction, y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define accuracy function\n",
    "@torch.no_grad()\n",
    "def accuracy(x, y, model):\n",
    "    prediction = model(x)\n",
    "    is_correct = (prediction > 0.5) == y\n",
    "    return is_correct.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define Validation loss calculation function\n",
    "@torch.no_grad()\n",
    "def val_loss(x, y, model):\n",
    "    prediction = model(x)\n",
    "    val_loss = loss_fn(prediction, y)\n",
    "    return val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch the required dataloaders\n",
    "trn_dl, val_dl = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model over 5 epochs\n",
    "train_losses, train_accuracies = [], []\n",
    "val_losses, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(epoch)\n",
    "    \n",
    "    train_epoch_losses, train_epoch_accuracies = [], []\n",
    "    val_epoch_accuracies = []\n",
    "    \n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "        train_epoch_losses.append(batch_loss)\n",
    "    train_epoch_loss = np.array(train_epoch_losses).mean()\n",
    "    \n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        is_correct = accuracy(x, y, model)\n",
    "        train_epoch_accuracies.extend(is_correct)\n",
    "    train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
    "    \n",
    "    for ix, batch in enumerate(iter(val_dl)):\n",
    "        x, y = batch\n",
    "        val_is_correct = accuracy(x, y, model)\n",
    "        val_epoch_accuracies.extend(val_is_correct)\n",
    "    val_epoch_accuracy = np.mean(val_epoch_accuracies)\n",
    "    \n",
    "    train_losses.append(train_epoch_loss)\n",
    "    train_accuracies.append(train_epoch_accuracy)\n",
    "    val_accuracies.append(val_epoch_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = np.arange(5)+1\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "\n",
    "plt.plot(epochs, train_accuracies, 'bo', label=\"Training accuracy\")\n",
    "plt.plot(epochs, val_accuracies, 'r', label='Validation accuracy')\n",
    "plt.gca().xaxis.set_major_locator(mtick.MultipleLocator(1))\n",
    "plt.title(\"Training and Validation accuracy  with 4k data points used during training\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.gca().set_yticklabels(['{:.0f}%'.format(x*100) for x in plt.gca().get_yticks()])\n",
    "plt.legend()\n",
    "plt.grid('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
