{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from imgaug import augmenters as iaa\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch the first 32 images in the training dataset\n",
    "data_folder = '~/data/FMNIST'\n",
    "fmnist = datasets.FashionMNIST(data_folder, train=True, download=True)\n",
    "\n",
    "# the augmenter needs the images as np arrays, that's why i convert it here\n",
    "tr_images = np.array(fmnist.data)\n",
    "tr_targets = np.array(fmnist.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Validation data\n",
    "val_fmnist = datasets.FashionMNIST(data_folder, download=True, train=False)\n",
    "val_images = np.array(val_fmnist.data)\n",
    "val_targets = np.array(val_fmnist.targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation to be performed.\n",
    "aug = iaa.Sequential(\n",
    "    [\n",
    "        iaa.Affine(translate_px={\"x\":(-10,10)}, mode='constant')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When performing augmentation of images, you can follow 2 approaches.\n",
    "\n",
    "1. Augmenting the batch one image at a time  \n",
    "2. Augmenting the whole batch at once. \n",
    "\n",
    "From the experiment of the time taken to do both, it's faster to augment the whole batch at once instead of one image at a time.\n",
    "\n",
    "This is the best practice in the industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset class to take input images and their augmenter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class MyDataste(Dataset):\n",
    "    def __init__(self, x, y, aug=None):\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.aug = aug\n",
    "    def __getitem__(self, index):\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        return x, y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def collate_fn(self, batch):\n",
    "        ims, classes = list(zip(*batch))\n",
    "        if self.aug:\n",
    "            self.aug.augment_images(images=ims)\n",
    "        ims = torch.tensor(ims)[:, None, :, :]/255\n",
    "        classes = torch.tensor(classes)\n",
    "        return ims, classes\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the train object\n",
    "train = MyDataste(tr_images, tr_images, aug=aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model architecture\n",
    "from torch.optim  import SGD, Adam\n",
    "import torch.nn as nn\n",
    "\n",
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Conv2d(1, 64, kernel_size=3),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 128, kernel_size=3),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(3200, 256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 10)     \n",
    "    )\n",
    "    # loss function and optimizer\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the train batch function in order to train on batches of the data\n",
    "def get_batch(x, y, model, opt, loss_fn):\n",
    "    model.train()\n",
    "    prediction = model(x)\n",
    "    batch_loss = loss_fn(prediction, y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the get_data function to fetch the training and validation DataLoaders\n",
    "def get_data():\n",
    "    train = MyDataste(tr_images, tr_targets, aug)\n",
    "    # DataLoader with the collate function\n",
    "    trn_dl = DataLoader(train, batch_size=64, collate_fn=train.collate_fn, shuffle=True)\n",
    "    val = MyDataste(val_images, val_targets)\n",
    "    val_dl = DataLoader(val, batch_size=len(val_images), collate_fn=val.collate_fn, shuffle=True)\n",
    "    return trn_dl, val_dl\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl, val_dl = get_data()\n",
    "model, loss_fn, optimizer = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train for 5 epochs\n",
    "for epoch in range(5):\n",
    "    print(epoch)\n",
    "    for ix, batch in enumerate(iter(trn_dl)):\n",
    "        x, y = batch\n",
    "        batch_loss = get_batch(x=x, y=y, model=model,opt=optimizer, loss_fn=loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred  = []\n",
    "ix = 24300\n",
    "for px in range(-5,6):\n",
    "    img = tr_images[ix]/255\n",
    "    img = img.view(28, 28)\n",
    "    img2 = np.roll(img, px, axis=1)\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "    img3 = torch.Tensor(img2).view(-1, 1, 28, 28)\n",
    "    np_output = model(img3).detach().numpy()\n",
    "    pred.append(np.exp(np_output)/np.sum(np.exp(np_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,10))\n",
    "plt.title(\"Probability of each class\")\n",
    "sns.heatmap(\n",
    "    np.array(pred).reshape(11,10),\n",
    "    annot=True,\n",
    "    ax=ax,\n",
    "    fmt='.2f',\n",
    "    xticklabels=fmnist.classes,\n",
    "    yticklabels=[str(i)+str('pixel') for i in range(-6,5)],\n",
    "    cmap='gray'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
